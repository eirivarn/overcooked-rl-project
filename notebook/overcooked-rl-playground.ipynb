{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ee01f63",
   "metadata": {},
   "source": [
    "# Exploring the Overcooked MDP and Environment\n",
    "\n",
    "_In this notebook we will:_\n",
    "1. Load and inspect the Overcooked MDP.  \n",
    "2. Wrap it in the RL-friendly `OvercookedEnv`.  \n",
    "3. Discover how to extract the underlying grid layout.  \n",
    "4. Visualize states with the provided `StateVisualizer`.  \n",
    "5. Step through a couple of actions and render the results.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9854d04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports\n",
    "import copy\n",
    "import math\n",
    "import os\n",
    "\n",
    "# Core MDP, actions, planners\n",
    "from overcooked_ai_py.mdp.overcooked_mdp import OvercookedGridworld\n",
    "from overcooked_ai_py.mdp.actions import Action\n",
    "from overcooked_ai_py.planning.planners import MediumLevelActionManager, NO_COUNTERS_PARAMS\n",
    "\n",
    "# RL wrapper\n",
    "from overcooked_ai_py.mdp.overcooked_env import OvercookedEnv\n",
    "\n",
    "# Visualization\n",
    "from overcooked_ai_py.visualization.state_visualizer import StateVisualizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a92ce5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Instantiate the MDP and Environment\n",
    "\n",
    "We’ll pick the “asymmetric_advantages” layout and a horizon of 400 timesteps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3067a275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Build MDP & Env\n",
    "mdp = OvercookedGridworld.from_layout_name(\"asymmetric_advantages\")\n",
    "env = OvercookedEnv.from_mdp(mdp, horizon=400)\n",
    "\n",
    "# Standard start state\n",
    "state0 = mdp.get_standard_start_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4105f7ae",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Visualize the Initial State\n",
    "\n",
    "`StateVisualizer` needs the raw layout grid.  Unfortunately the MDP doesn’t expose it as `.terrain`, but either as `.terrain_mtx` or `.grid`.  We can fall back gracefully.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a25d19c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid size: 5×9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X'],\n",
       " ['O', ' ', 'X', 'S', 'X', 'O', 'X', ' ', 'S'],\n",
       " ['X', ' ', ' ', ' ', 'P', ' ', ' ', ' ', 'X'],\n",
       " ['X', ' ', ' ', ' ', 'P', ' ', ' ', ' ', 'X'],\n",
       " ['X', 'X', 'X', 'D', 'X', 'D', 'X', 'X', 'X']]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 3: Extract the layout grid\n",
    "try:\n",
    "    grid = mdp.terrain_mtx\n",
    "except AttributeError:\n",
    "    grid = mdp.grid\n",
    "\n",
    "print(f\"Grid size: {len(grid)}×{len(grid[0])}\")\n",
    "grid  # display the 2D list of chars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "244be312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'/var/folders/x9/scyyg02s20v0759sw_qxdlqc0000gn/T/overcooked_visualized_state_4babe114-21c8-11f0-b0fc-665cc768392c.png'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 4: Render initial state inline\n",
    "viz = StateVisualizer(tile_size=60, is_rendering_action_probs=False)\n",
    "viz.display_rendered_state(state0, grid=grid, ipython_display=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c342c5a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Single‐Step Transition\n",
    "\n",
    "Let’s apply both agents choosing `INTERACT` at t=0, then visualize the result.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "01056f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged events: {'tomato_pickup': [False, False], 'useful_tomato_pickup': [False, False], 'tomato_drop': [False, False], 'useful_tomato_drop': [False, False], 'potting_tomato': [False, False], 'onion_pickup': [False, False], 'useful_onion_pickup': [False, False], 'onion_drop': [False, False], 'useful_onion_drop': [False, False], 'potting_onion': [False, False], 'dish_pickup': [False, False], 'useful_dish_pickup': [False, False], 'dish_drop': [False, False], 'useful_dish_drop': [False, False], 'soup_pickup': [False, False], 'soup_delivery': [False, False], 'soup_drop': [False, False], 'optimal_onion_potting': [False, False], 'optimal_tomato_potting': [False, False], 'viable_onion_potting': [False, False], 'viable_tomato_potting': [False, False], 'catastrophic_onion_potting': [False, False], 'catastrophic_tomato_potting': [False, False], 'useless_onion_potting': [False, False], 'useless_tomato_potting': [False, False]}\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhwAAAEsCAIAAAAHDv0bAAAJU0lEQVR4nO3dT4icZx0H8Jmy3eQQIoQaG5VWoisWJIfOHpqL7h7VtCC0elCEVpiclF69WGqhN6HgafcSqBjRHoR2g9fES3rY8RAFwWgwgjaNGFRySDb1D17eeUNn2X13vu/svM98Pqcnyzvv++Zh33z5zS/v8/Q3hj0AiHgkcxoAECoABKlUAIgRKgDECBUAYoQKADFCBYAYoQJAjFABIEaoABAjVACIESoAxAgVAGKECgAxQgWAGKECQIxQASBGqAAQI1QAiBEqAMQIFQBihAoAMUIFgBihAkCMUAEgRqgAECNUAIgRKgDECBUAYoQKADFCBYAYoQJAjFABIEaoABAjVACIESoAxAgVAGKECgAxQgWAGKECQIxQASBGqAAQI1QAiBEqAMQIFQBihAoAMUIFgBihAkCMUAEgRqgAECNUAIgRKgDECBUAYoQKADFCBYAYoQJAjFABIEaoABAjVACIWerNgcFwoxqPNs/vefyZc+Pju+La1t5/r3nzxFd/2euaP//iS4d9C53U9Bnsoi7+u/GPR5/odY1KBYAYoQJAjFABYD56Kk2/h10+dqIaP/mFb008ZuXLL1fjm796sxrv3L0zxZ1CmTyDzBuVCgAxQgWAGKECwGx7KqleyJNfHH/2+Ceemnie458c//xTay9W499v/XA/twpF8gzSFSoVAGKECgAxQgWA2fZUUr2QYydPN7q5Y483Ox5K5RmkK1QqAMQIFQBihAoAs+2ppHohd2/f2LM389Dxt8bHwyLzDNIVKhUAYoQKADFCBYDZ9lRSvZCbV96c+P/uj31s3IO5+/74szev/Hg/twfF8wzSFSoVAGKECgAxQgWA9nsq9b2vf3Pxe5FeSH1vleuX3tjzujt3/77X/UOxPIN0kUoFgBihAkCMUAEgZmk/e1/Xf15/16TeI5nlnttQki4+g9Ncl7KpVACIESoAxAgVAGKWUntfNzXNdaEkXXwGp7kuZVOpABAjVACIESoAxCyl9r7ebc2i0eb5yeeZ4rof3Gr0UZhrXXwGYTcqFQBihAoAMUIFgJilafa+nmbtoGmue7T32T2Ph67o4jMIu1GpABAjVACIESoAxCzV92Zouv/8NGsH/enyhQNf93Nrr+/jrwbd0MVnEHajUgEgRqgAECNUAIhZqu81ff3SG40+PM3aQdNcF0riGaQkKhUAYoQKADFCBYCYpWk+bO0gOFyeQeaNSgWAGKECQIxQAWA+eirTrFkETM8zyLxRqQAQI1QAiBEqAMT0N4a9zjlzbuOwb4E5dW3rfK9rSv19Prs1u2tdPdcr0rUO/j6rVACIESoAxAgVAGKECgAxQgWAGKECQIxQAWA+1v4C2M+7I228s1Lquyldp1IBIEaoABAjVACI0VOhKKNe9xazO3PYNwBBKhUAYoQKADFCBYAYPRWKtbm5OfHnKysrvcO2vr5+2LcArVCpABAjVACIESoAxOipAK3bHoz7W6ujYeQ8Dzr4TtIiUKkAECNUAIgRKgDE6KkAM1Xvi1AelQoAMUIFgBihAkCMngrFGg69xwCzplIBIEaoABAjVACI0VMBWvHMs/WeVrv9rXff8e7LvFCpABAjVACIESoAxAgVAGKECgAxQgWAGKECQIz3VIBWjDZXq/FguN3q+XunrPM2L1QqAMQIFQBihAoAMXoqQCsetNznaPv8HIxKBYAYoQJAjFABIEZPBWhdfb+Th/dZOfgxzCeVCgAxQgWAGKECQIyeCkUZ9Lr4nftGr3Rnnztf+1N9PHb17fE89Pv9Pc9ZP575oVIBIEaoABAjVACI0VMBWte0/6Ff0l0qFQBihAoAMUIFgJhieypn3xvN7FpXTw1mdi2AeaZSASBGqAAQI1QAiBEqAMQIFQBihAoAMUIFgJhi31OpvzvSxjsr3k0B+DCVCgAxQgWAGKECQEyxPRUW06g37HXNmcO+AQhSqQAQI1QAiBEqAMToqVCszc3NiT9fWVnpHbb19fXDvgVohUoFgBihAkCMUAEgZiF6Ktu98dpfq71B5DwPpjgPQKlUKgDECBUAYoQKADEL0VPZrS8CQJZKBYAYoQJAjFABIGbheiosjuGwe3urQNepVACIESoAxAgVAGKK7ak882z9+/R2v1t/953J+3YALBqVCgAxQgWAGKECQIxQASBGqAAQI1QAiBEqAMQU+57KaHO1Gg+G262ev3fKGlMA/6dSASBGqAAQI1QAiCm2p/Kg5T5H2+cH6CKVCgAxQgWAGKECQEyxPZXd9jt5eJ+Vgx8DwIepVACIESoAxAgVAGIWoqdy9rnztT/Vx2NX396oxv1+f89z1o9nfgx6Xex7+V2iHCoVAGKECgAxQgWAmIXoqTTtf+iXAByMSgWAGKECQIxQASCmv2FbEBo6vfq1ajz4yver8UdOrlTjf96+Xo1Hl35QjW9s/9x8m2cKplIBIEaoABAjVACIWYj3VJje6aefr8ZrL/6kGt+5c6ca/+W996vxkSMfnXh8nf6KeaY8KhUAYoQKADFCBYAY76mwLy+88ttq/GBp3C+5d+/enp89evRoNX70g79V47de/bzZN88URqUCQIxQASBGqAAQ4z0V9qW+rtdfb91uNGs7OzvV+LHHx+fBPFMelQoAMUIFgBihAkCMngr7Ut8fZXm52Xsqy8vLE89TZ48W80wZVCoAxAgVAGKECgAx1v5iX04PXqjGay9dnLifyv3796vxkSNHqvGJEyeq8ZUL36zG//3Pv8fn/PZPD3zOyxe+UcweLeaZrlOpABAjVACIESoAxOip0NinV79ejQfnXqnGx09+phr/6/YfqvFo69Vq/Mftn1Vje7SYZ8qjUgEgRqgAECNUAIix9heN1fsi9XFT9mgxz5RHpQJAjFABIEaoABCjp8JUptkHpe09WkpinukKlQoAMUIFgBihAkCMtb9o7PTTz0f2Qfnd5R9V46fWvhPZo2Wa92bmjXmmi1QqAMQIFQBihAoAMXoqNNbGPii/vvRaZI+WkphnukilAkCMUAFAqAAwf6z9xVzsg5Lao6Uk5pku8vUXADFCBYAYoQJAjJ4KjdkHZTbMM12kUgEgRqgAECNUAIjRU6Gx+rpbay9dnGIflO+affNMYVQqAMQIFQBihAoAMXoqNHZj9FY17vcfmbgPymMfn7wPSr2PYo0v80x5VCoAxAgVAGKECgC9lP8BWYk8Au8IH3oAAAAASUVORK5CYII=",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'/var/folders/x9/scyyg02s20v0759sw_qxdlqc0000gn/T/overcooked_visualized_state_5affef5c-21c8-11f0-b0fc-665cc768392c.png'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 5: Step the MDP directly\n",
    "joint_action = (Action.INTERACT, Action.INTERACT)\n",
    "next_state, info = mdp.get_state_transition(state0, joint_action)\n",
    "print(\"Logged events:\", info['event_infos'])\n",
    "\n",
    "# Visualize\n",
    "viz.display_rendered_state(next_state, grid=grid, ipython_display=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40dbd313",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Featurizations\n",
    "\n",
    "### 5.1 Lossless Mask Encoding\n",
    "\n",
    "A stack of boolean masks, one channel per terrain/agent/object layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "40287582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask shape per player: (9, 5, 26)\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Lossless encoding\n",
    "mask_p0, mask_p1 = mdp.lossless_state_encoding(state0)\n",
    "print(\"Mask shape per player:\", mask_p0.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518fc60e",
   "metadata": {},
   "source": [
    "### 5.2 Hand-Crafted Feature Vector\n",
    "\n",
    "Distances, counts, relative positions, etc., for CNN-free RL agents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e0e618ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature vector length per player: 96\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Hand-crafted encoding (requires planner)\n",
    "mlam = MediumLevelActionManager.from_pickle_or_compute(mdp, NO_COUNTERS_PARAMS)\n",
    "features = mdp.featurize_state(state0, mlam, num_pots=2)\n",
    "print(\"Feature vector length per player:\", features[0].shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6299b1e0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Potential Function for Reward Shaping\n",
    "\n",
    "A heuristic estimate of future return under greedy planning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d0b2842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State potential: 30.633689117862914\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Compute potential\n",
    "phi = mdp.potential_function(state0, mlam.motion_planner, gamma=0.99)\n",
    "print(\"State potential:\", phi)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b76c1f7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Rolling Out a Trajectory\n",
    "\n",
    "We can use `OvercookedEnv.get_rollouts` to simulate a pair of random agents and visualize.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d7550e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg rew: 0.00 (std: 0.00, se: 0.00); avg len: 400.00; : 100%|██████████| 1/1 [00:00<00:00, 15.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing MotionPlanner\n",
      "Computing MotionPlanner to be saved in /Users/eirikvarnes/code/overcooked-rl-project/overcooked_ai/src/overcooked_ai_py/data/planners/asymmetric_advantages_mp.pkl\n",
      "It took 0.03780508041381836 seconds to create mp\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9c77e6b56884cdcac93d7ff241ff671",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='timestep', max=399), Output()), _dom_classes=('widget-in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 9: Generate and visualize one rollout\n",
    "from overcooked_ai_py.agents.agent import AgentPair, RandomAgent\n",
    "\n",
    "agent_pair = AgentPair(RandomAgent(all_actions=True), RandomAgent(all_actions=True))\n",
    "traj = env.get_rollouts(agent_pair, num_games=1, display=False, info=True)\n",
    "\n",
    "# Render trajectory inline\n",
    "viz.display_rendered_trajectory(traj, trajectory_idx=0, ipython_display=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91c2755",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "In this notebook we have:\n",
    "\n",
    "- **Built** the core `OvercookedGridworld` MDP  \n",
    "- **Wrapped** it in `OvercookedEnv` for standard `reset/step` RL usage  \n",
    "- **Visualized** raw states and transitions with `StateVisualizer`  \n",
    "- **Extracted** both mask stacks and hand-crafted feature vectors  \n",
    "- **Computed** a potential shaping function  \n",
    "- **Simulated** complete rollouts  \n",
    "\n",
    "You can now hook in your favorite RL algorithm—using the featurizations or raw mask inputs—to train agents to collaborate in Overcooked.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "overcooked",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
